\chapter{Computational methods for perturbative constructive gravity}
\label{chapter_computational_methods}

\textit{The results from the previous chapter provide us with a comprehensive algorithm for the perturbative construction of gravitational theories. While consisting almost entirely of linear algebra, the execution of the algorithm is not feasible without the help of the computer. Therefore, we dedicate this section to the presentation of two Haskell libraries: the first one, \texttt{sparse-tensor}, implements the generation of Lorentz invariant perturbation ansätze. The second library, \texttt{safe-tensor}, is designed for safe and efficient evaluation and solution of the equivariance equations.}

\section{Ansatz generation}
A central finding of Chap.\ \ref{chapter_perturbation} is that the perturbation ansätze inherit the Lorentz invariance of the expansion point. This has important practical ramifications: for example, instead of the 10 coefficients $a_A$ in the expansion of a metric Lagrangian, we can just work with the one-dimensional Lorentz invariant coefficient $c\cdot J_A^{ab} \eta_{ab}$. That means, before even considering the equivariance equations, the dimensionality of the ansatz can already be reduced a lot.

It can be shown that a constant Lorentz invariant tensor, say $T^{abcd}$, is comprised of the Minkowski metric $\eta$ and the totally antisymmetric symbol $\epsilon$ \cite{}, such that for this example
\begin{equation}\label{generic_4_ansatz}
  T^{abcd} = A \cdot \epsilon^{abcd} + B \cdot \eta^{ab} \eta^{cd} + C \cdot \eta^{ac} \eta^{bd} + D \cdot \eta^{ad} \eta^{bc}.
\end{equation}
The coefficients $A,B,C,D$ can be chosen freely, leaving us with 4 degrees of freedom instead of 64. If the tensor shall have certain symmetries, e.g.\ the symmetries of an area metric tensor, we find an ansatz by applying the symmetry projections to the generic rank-4 ansatz \eqref{generic_4_ansatz}, which yields in this case
\begin{equation}
  S^{abcd} = A \cdot \epsilon^{abcd} + \frac{C - D}{2} \left( \eta^{ac}\eta^{bd} - \eta^{ad}\eta^{bc} \right).
\end{equation}
Two coefficients $A$ and $\frac{C-D}{2}$ would parameterize such an ansatz.

In order to execute the perturbative construction algorithm, we need to find a basis for the ansätze \eqref{ansatz_reduced} up to the desired perturbation order. This is, in principle, achieved by listing all possible products of $\epsilon$ and $\eta$ and assigning to each term a unique coefficient. Each product will contain at most one $\epsilon$, because the product of two $\epsilon$ symbols amounts to a linear combination of products of Minkowski metrics.

The ansätze we want to construct exhibit certain symmetries. For one, the field bundle is symmetric (e.g.\ the symmetry of a metric or the symmetries of an area metric), but there are also symmetries inherited from second derivatives or the product of perturbations. Consider, for example, the area metric ansatz
\begin{equation}
  a_{ABC}^{\hphantom{ABC}I} H^A H^B H^C_{\hphantom CI}.
\end{equation}
Expressed using spacetime indices, this ansatz reads
\begin{equation}
  a_{abcd\ efgh\ pqrs}^{\hphantom{abcd\ efgh\ pqrs}ij} H^{abcd} H^{efgh} H^{pqrs}_{\hphantom{pqrs}ij}.
\end{equation}
Of course, the individual index sets $abcd$, $efgh$, and $pqrs$ inherit the area metric symmetries from the perturbation $H$. The indices $i,j$ are symmetric due to the commutativity of partial derivatives. The product of $H^{abcd}$ and $H^{efgh}$ enforces a block symmetry of the ansatz under the exchange of the index sets $abcd$ and $efgh$. We construct such an ansatz like before, by applying the respective projections to the ansatz, which collapses many individual terms with different coefficients to symmetric terms sharing a common prefactor. Note that we deal with the mixed index positions by constructing a purely covariant ansatz and raising the derivative indices using an $\eta$ afterwards, e.g.
\begin{equation}
  a_{ab}^{\hphantom{ab}ij} H^{ab}_{\hphantom{ab}ij} = \eta^{ii^\prime} \eta^{jj^\prime} \tilde a_{abi^\prime j^\prime} H^{ab}_{\hphantom{ab}ij}.
\end{equation}

One thing has not been considered so far: It is not clear, \emph{a priori}, whether the constructed ansätze really form a \emph{basis}. We need to be sure that a representation like Eq.\ \eqref{generic_4_ansatz} uniquely determines the ansatz. In general, this will \emph{not} be the case, as the ansatz
\begin{equation}\label{generic_6_ansatz}
  \begin{aligned}
    T^{abcdef} = {} & A_1 \cdot \epsilon^{abcd} \eta^{ef} + A_2 \cdot \epsilon^{abce} \eta^{df} + A_3 \cdot \epsilon^{abcf} \eta^{de} + A_4 \cdot \epsilon^{abde} \eta^{cf} + \dots \\
    {} & \dots + A_{16} \cdot \eta^{ab} \eta^{cd} \eta^{ef} + A_{17} \cdot \eta^{ab} \eta^{ce} \eta^{df} + \dots
  \end{aligned}
\end{equation}
for a rank-6 tensor demonstrates. The 15 terms of the type $\epsilon^{abcd}\eta^{ef}$ are linearly dependent via the identity
\begin{equation}
  0 = 5 \epsilon^{\lbrack abcd}\eta^{e\rbrack f} = \epsilon^{abcd} \eta^{ef} - \epsilon^{abce} \eta^{df} - \epsilon^{abed} \eta^{cf} - \epsilon^{aecd} \eta^{bf} - \epsilon^{ebcd} \eta^{af}.
\end{equation}

Because of this circumstance, we cannot consider two ansatz terms distinct just because their representations as linear combinations of $\epsilon$ and $\eta$ products differ. Rather, we need to inspect the actual \emph{components} of the tensors in order to make a decision. For the ansatz in Eq.\ \eqref{generic_6_ansatz}, this would mean that we evaluate the $4^6$ components $T^{abcdef}$, which gives 4096 linear combinations of the 30 coefficients $A_1\dots A_{30}$. An ansatz without linearly dependent terms would exhibit 30 linearly independent combinations, which could be checked by calculating the rank of the $4096\times 30$ matrix representing the linear combinations---it should be equal to 30. In this case, it will be less than 30 because we already know of at least one linear dependence. Gaussian elimination of the matrix tells us which coefficients can be used as basis: exactly those whose corresponding column contains, for some row, the first non-zero entry in this row. The other coefficients are linearly dependent on the basis coefficients and can thus safely be set to zero.

Let us demonstrate this reduction of linearly dependent ansatz coefficients with the help of an example. Pretend that, after evaluation of a tensor with four indices, the matrix
\begin{equation}
  \begin{blockarray}{ccccc}
    & A & B & C & D \\
    \begin{block}{c(cccc)}
      0000 & 1 & 1 & -2 & 0 \\
      0101 & 0 & 2 & -6 & -4 \\
      0123 & 3 & 0 & 3 & 1 \\
    \end{block}
  \end{blockarray}
\end{equation}
is obtained. In practice, matrices will often reduce to such simple forms, because they contain many zero or duplicate rows that can be removed. Gaussian elimination may yield (depending on the pivoting)
\begin{equation}
  \begin{blockarray}{cccc}
    A & B & C & D \\
    \begin{block}{(cccc)}
      3 & 0 & 3 & 1 \\
      0 & 2 & -6 & -4 \\
      0 & 0 & 0 & \frac{5}{3} \\
    \end{block}
  \end{blockarray}\raisebox{-3ex}{,}
\end{equation}
from which we read off the linearly independent columns $A$, $B$, and $D$. The superfluous ansatz coefficient $C$ can be set to zero.

The Haskell package \texttt{sparse-tensor}\footnote{See \cite{Reinhart_2019_sparse-tensor}. The source code is publicly available at \url{https://github.com/TobiReinhart/sparse-tensor}.} exports the module \texttt{\Code{Math.Tensor.LorentzGenerator}}, which implements the procedure outlined above. Haskell is a purely functional language with lazy semantics by default. \cite{Marlow_2010} In practice, this means that the programmer does not modify state but composes expressions, which are evaluated only when asked for. Consider, for example, a routine that sums up the elements of an array. First, let us look at an implementation in C.
\begin{code}
  \begin{minted}[frame=single,linenos]{C}
int sum(int array[], int length) {
  int result = 0;

  for (int i = 0; i < length; ++i) {
    result += array[i];
    // perform_side_effect();      <-- possible side effect!
  }

  return result;
}
  \end{minted}
  \captionof{listing}{C implementation of the \texttt{sum} function.}
\end{code}
Note how state---in the form of the \texttt{result} variable---is created, modified, and eventually returned. At any point of the programme, it is possible to perform arbitrary side effects, which could modify the input data, alter the local state (consisting of counter variable \texttt{i} and result variable \texttt{result}), print something to the user's screen, and so on.

In Haskell, on the other hand, a na\"ive\footnote{Performance considerations put aside.} implementation of the \texttt{sum} function reads quite differently.
\begin{code}
  \begin{minted}[frame=single,linenos]{haskell}
sum :: [Int] -> Int
sum xs = go 0 xs
  where
    go acc [] = acc
    go acc (y:ys) = go (acc+y) ys
  \end{minted}
  \captionof{listing}{Haskell implementation of the \texttt{sum} function.}
  \label{code_haskell_sum}
\end{code}
The \texttt{sum} function in Listing \ref{code_haskell_sum} demonstrates how functional programming approaches certain tasks. The input is a \texttt{List} of integers, a functional data structure that matches either the empty list \mintinline{haskell}{[]} or an integer appended to some list, e.g.\ \mintinline{haskell}{5 : xs}. Data is \emph{consumed} by matching on patterns and results are \emph{produced} by building up expressions, in this case repeated applications of the \mintinline{haskell}{(+)} function in line 5. It is, by design, impossible to slip in side effects, which is why functions in Haskell are \emph{pure}. This leads to the important property called \emph{referential trasparency}, meaning that expressions can be replaced by their values without changing the behaviour of the programme.

Because of its purity and, importantly, the powerful type system based on System F \cite{Girard_1972}, Haskell allows to write programmes that are both efficient and safe. As we will see, the objects we are concerned with have natural representations as functional data types and the manipulations that need to be performed translate into efficient, pure functions operating on these types.

We will only sketch the implementation of the ansatz generation procedure outlined above. Performance optimizations like strictness annotations and unpacking are not given explicitly. For all details, see Ref.\ \cite{Reinhart_2019} and the documentation \cite{Reinhart_2019_sparse-tensor} of the package. There are more differences between the presentation here and the production code, which have been introduced deliberately for lighter reading.

As already mentioned, an ansatz has a representation as a functional data structure. Let us begin with the individual $\eta$ and $\epsilon$ tensors in Listing \ref{code_haskell_eta_epsilon}.
\begin{code}
  \begin{minted}[frame=single]{haskell}
-- data type representing an \eta^{a b} tensor
data Eta     = Eta     Char Char           deriving (Eq, Ord)
-- data type representing an \epsilon^{a b c d} tensor
data Epsilon = Epsilon Char Char Char Char deriving (Eq, Ord)
  \end{minted}
  \captionof{listing}{Haskell representation of $\eta$ and $\epsilon$ tensors.}
  \label{code_haskell_eta_epsilon}
\end{code}
These types are, essentially, named wrappers for the index labels. We also need a type that represents a coefficient. For our purposes, an integer prefactor (because we will never perform division) and a variable label, also an integer, will suffice. See Listing \ref{code_haskell_coefficient}.
\begin{code}
  \begin{minted}[frame=single]{haskell}
-- data type representing a coefficient c * A_i
data Coeff = Coeff Int Int
  \end{minted}
  \captionof{listing}{Haskell representation of a scaled ansatz coefficient.}
  \label{code_haskell_coefficient}
\end{code}
Now, the central type for the generation of ansätze is a List of trees, called \emph{forest}. From now on, we leave $\epsilon$ tensors out of the picture. As they appear at most once, we will always sort the trees such that an $\epsilon$---if present---is the root. In everything that follows, a distinction has to be made when operating on the roots of ansatz trees, but everything else concerns only trees of $\eta$ tensors. With this caveat, the data type is as shown in Listing \ref{code_haskell_ansatz_forest}.
\begin{code}
  \begin{minted}[frame=single]{haskell}
data Forest a b = Forest [(a, Forest a b)] | Leaf b
type Ansatz = Forest Eta Coeff
  \end{minted}
  \captionof{listing}{Haskell representation of an ansatz consisting only of $\eta$ tensors.}
  \label{code_haskell_ansatz_forest}
\end{code}
We will always keep the forests sorted in two ways: the list of trees \mintinline{haskell}{[(Eta, Forest Eta Coeff)]} is sorted, meaning that e.g.\ $\eta^{ab}$ comes before $\eta^{cd}$, but also all $\eta$ tensors appearing in the inner forest must come after the outer $\eta$ tensor---so it is forbidden to insert an $\eta^{ab}$ below a node $\eta^{cd}$.
\begin{code}
  \begin{minted}[frame=single]{haskell}
    Eta 'a' 'b'
     |
     +---- Eta 'c' 'd'
     |      |
     |      +---- Eta 'e' 'f' - Coeff 1 1
     |
     +---- Eta 'c' 'e'
     |      |
     |      +---- Eta 'd' 'f' - Coeff 1 2
     |
     +---- Eta 'c' 'f'
            |
            +---- Eta 'd' 'e' - Coeff 1 3

    Eta 'a' 'c'
     |
     +---- Eta 'b' 'd'
     |      |
     |      +---- Eta 'e' 'f' - Coeff 1 4
     |
     +---- Eta 'b' 'e'
     |      |
     |      +---- Eta 'd' 'f' - Coeff 1 5
     |
     +---- Eta 'b' 'f'
            |
            +---- Eta 'd' 'e' - Coeff 1 6
    ...
  \end{minted}
  \captionof{listing}{First 6 $\eta$-only terms of an ansatz tensor with 6 indices.}
  \label{code_haskell_ansatz6}
\end{code}
An example representation of the first 6 $\eta$-only terms for the ansatz
\begin{equation}
  A_1 \cdot \eta^{ab} \eta^{cd} \eta^{ef} + \dots + A_6 \cdot \eta^{ac} \eta^{bf} \eta^{de}
\end{equation}
is given in Listing \ref{code_haskell_ansatz6}. Such a sorted tree is easily traversed for updates, insertions, deletions, \emph{et cetera}. Also, the evaluation of specific components is greatly simplified: \mintinline{haskell}{Eta 'a' 'b'} only has to be evaluated once, and very importantly, for components where $\eta^{ab} = 0$, the whole tree can be discarded. Let us give one example of an operation on ansatz forests, namely the sum of two ansatz forests in Listing \ref{code_haskell_ansatz_sum}.
\begin{code}
  \begin{minted}[frame=single,linenos]{haskell}
addAnsatz :: Ansatz -> Ansatz -> Ansatz
addAnsatz (Leaf coeff1) (Leaf coeff2) = Leaf (addCoeffs coeff1 coeff2)
  where
    addCoeffs :: Coeff -> Coeff -> Coeff
    addCoeffs (Coeff c1 var1) (Coeff c2 var2)
      | var1 == var2 = Coeff (c1+c2) var1
      | otherwise    = error "adding distinct variables"
addAnsatz (Forest fs1) (Forest fs2) = Forest (addForests fs1 fs2)
  where
    addForests :: [(Eta, Forest Eta Coeff)]
               -> [(Eta, Forest Eta Coeff)]
               -> [(Eta, Forest Eta Coeff)]
    addForests [] ys = ys
    addForests xs [] = xs
    addForests (x:xs) (y:ys) =
        case fst x `compare` fst y of
          LT -> x : addForests xs (y:ys)
          EQ -> let innerAnsatz = addAnsatz (snd x) (snd y)
                in  (fst x, innerAnsatz) : addForests xs ys
          GT -> y : addForests (x:xs) ys
addAnsatz _ _ = error "cannot add incompatible ansätze"
  \end{minted}
  \captionof{listing}{Sum of two ansatz forests.}
  \label{code_haskell_ansatz_sum}
\end{code}
The occurrence of \mintinline{haskell}{error} functions means that the function \mintinline{haskell}{addAnsatz} is \emph{partial}, i.e.\ does not compute an output for any input. This could be cured by refining the return type of the function, but doing so is not really necessary for this use case, as the input is under our control: we will neither add incompatible ansätze, nor will two leaves with distinct variables be added. The curious reader may be referred to the next section, where we actually introduce methods for catching such runtime errors already at the type level.

Ansatz generation proceeds as follows: starting with the empty forest, we consider each possible ansatz term separately, one at a time, for example $\eta^{ab} \eta^{cd} \eta^{ef}$. For each such term, it is first checked whether the ansatz already contains the term, utilizing fast lookup in the sorted forest. If it is contained, we can discard the term and proceed with the next one. If, on the other hand, the term is \emph{new}, it is assigned a new variable, symmetrized, and added to the ansatz.

When all possible ansatz terms have been added (or discarded, for that matter), the linear dependencies are identified and removed, like explained before. For the linear algebra part, the package \texttt{hmatrix} is used together with a custom implementation of Gaussian elimination that is tested for sufficient stability.

For the handling of larger ansätze---up to 18 indices at the time of writing, which is enough for fourth-order area metric Lagrangians---a second mode has been implemented. In order for the matrix not to become too large, its is checked \emph{before insertion} whether a given symmetrized term would be linearly dependent on the already existing terms. This entails keeping track of the evaluation matrix, as re-evaluating the ansatz tensors for each term that is added would be too expensive. However, we do not have to perform Gaussian elimination, because it is not necessary to identify which column would introduce a rank defect---it is always the new one, because we ensure that the matrix rank is maximal with our construction. So, fast and numerically stable singular value decomposition can be used for computing ranks.

Overall, the second method is a bit slower for ansätze with 14 indices (needed for third-order area metric Lagrangians) than the first method, taking a couple of seconds to compute on modern workstation hardware. For the fourth-order ansätze, however, it is the only option. With all the optimization work that has been done, like exploting the symmetries in order to reduce the number of terms that are even considered for insertion or, likewise, reducing the number of index combinations to be probed (see \cite{Reinhart_2019} or the source code and documentation \cite{Reinhart_2019_sparse-tensor}), the computation times have been reduced drastically. The largest fourth-order ansätze with 18 indices are computed within half an hour, using a few gigabytes of memory. To the knowledge of the author, the methods developed for the canonical approach \cite{Schneider_2017} (to which this method is applicable as well) do not achieve this efficiency.

We will encounter the generated ansätze in Chap.\ \ref{chapter_weak_area} when constructing perturbative area metric gravity. But first, let us walk through the second Haskell package developed in the course of this thesis.

\section{Equivariance equations}
In principle, \texttt{sparse-tensor} provides the machinery for setting up and solving the equivariance equations. It even contains some safeguards against composing tensors of incompatible ranks, but not nearly enough in order to safely mirror Eqns.\ \eqref{prolong_0}--\eqref{prolong_2} in a Haskell programme. For this purpose, the package \texttt{safe-tensor}\footnote{See \cite{Alex_2020_safe-tensor}. The source code is publicly available at \url{https://github.com/nilsalex/safe-tensor}, the package is also available via hackage at \url{https://hackage.haskell.org/package/safe-tensor}.} has been developed, which implements index-based tensor calculus as known from mathematical physics. \texttt{safe-tensor} makes it comparably easy and, above all, \emph{safe} to perform all kinds of operations on tensors, including transpositions of indices, contractions, symmetrizations, tensor products, and tensor sums.

Central for the design of the tensor type provided by the package is the \emph{generalized rank} of a tensor. The tensors we deal with, a good example being the Gotay-Marsden coefficients $\gmc{A}{B}{n}{m}$, can be considered as multilinear maps over \emph{different} vector spaces. Applying this interpretation to $C$, we get a map
\begin{equation}
  C \colon V_\text{area}^\ast \times V_\text{area} \times V^\ast \times V \rightarrow \mathbb R
\end{equation}
with $V_\text{area}$ being a fibre of the area metric bundle and $V$ a tangent space to the base manifold.

Concrete calculations employ a basis $(e_i)_{i=1\dots n}$ of $V$ and a corresponding dual basis $(\epsilon^i)_{i=1\dots n}$ of $V^\ast$, where $n$ denotes the dimension of the base manifold. Such bases carry over to fibres like $V_\text{area}$ or $V_\text{metric}$. Representations like $\gmc{A}{B}{n}{m}$ for $C$ are understood in terms of these bases. For the definition of the generic rank of this representation, we assign each type of vector space a label, e.g.\ ST\footnote{Meaning: tangent space to spacetime.} for $V$ and STArea for $V_\text{area}$. The indices corresponding to each space and the dual complete the list of labels to the generic rank. For the example of the Gotay-Marsden coefficients, we have
\begin{equation}
  \operatorname{rank}(\gmc{A}{B}{n}{m}) = \{(\underbrace{\text{ST}}_{\text{label}}, \underbrace{4}_{\text{dimension}}, \underbrace{\{n\}}_{\text{contravariant}}, \underbrace{\{m\}}_{\text{covariant}}), (\text{STArea}, 21, \{A\}, \{B\})\}.
\end{equation}
Note that the contravariant and covariant indices are each provided as \emph{set}, i.e.\ they cannot contain duplicates and have no specific order\footnote{For this reason, we are allowed to sort the index lists in our implementation, which results in more efficient operations.}. It is permitted, however, for the set of covariant indices and the set of contravariant indices to have a non-empty intersection---these are candidates for contractions.

Let us consider more examples:
\begin{align}
  \operatorname{rank}(\eta^{ab}) = {} & \{(\text{ST}, 4, \{a,b\}, \{\})\} \\
  \operatorname{rank}(\eta^{ba}) = {} & \{(\text{ST}, 4, \{a,b\}, \{\})\} \\
  \operatorname{rank}(\eta_{\heartsuit}) = {} & \{(\text{STSym2}, 10, \{\}, \{\heartsuit\})\}\footnotemark \\
  \operatorname{rank}(\gmc{B}{A}{p}{p} N^A) = {} & \{(\text{ST}, 4, \{p\}, \{p\}), (\text{STArea}, 21, \{A,B\}, \{A\})\} \label{eq_to_contract}
\end{align}
\footnotetext{Index labels can be arbitrary!}

The contraction of a rank is obtained by removing duplicate indices. If as a result there are no indices associated to a vector space, it is also removed from the generalized rank. Revisiting the previous example \eqref{eq_to_contract}, application of the contraction yields
\begin{equation}
  \operatorname{contract}(\operatorname{rank}(\gmc{B}{A}{p}{p} N^A)) = \{(\text{STArea}, 21, \{B\}, \{\})\}.
\end{equation}

